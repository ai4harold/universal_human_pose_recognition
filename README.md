# 通用的人体姿态分析系统
## 简述
  该方法提出了一种建立在边缘计算设备上的人体姿态观察与分析方法，不仅满足了边缘计算中实施行的要求（试验结果在jetson nano上通过安装TensoRT tf-pose实现了达到8fts的效果），而且通过第二路数据的传输采用人工智能工作站使用openpose对现场视频进行进一步分析，并将分析数据使用微软PowerBI进行可视化分析。 

## 产品设计与技术实现方法
### 设计目的
对目标人群的身体姿态进行观察、分析目标人群的正常姿态和步态或是非正常姿态和步态的判断，用于在运动中比对或是调整其姿态或是步态；其在社会治安、自动驾驶、驾驶员姿态监测、体育运动、健身减肥、医学领域中的疾病康复等具有重要的作用。传统的人体姿态识别：通常是基于身体绑定传感器和动作捕捉装置，采集人体18个关键点的三维坐标，从而通过计机3D建模软件生成人体的动作模型。需要待分析目标人群与科研该方法的局限性还在于穿着通过传感器的运动捕捉装置本身是需要捆绑在待分析人员的身体上，再加上数据线的缠绕和长度有限，又要依赖一台计算机进行分析，偏置运动产生束缚和影响，更难以连续多空间的对待分析目标进行跟踪分析。

### 设计目标
利用摄像头为姿态捕捉设备，用人工智能图像处理的方法对人体的姿态进行数字化和数据分析。我们采用人工智能的多个算法，采用人工智能的视觉识别的方法定位人体关键点，并通过建立“人体关键点之间线段”技术识别人体姿态，并采用大数据技术对数据进行记录，利用采集到的数据进行可视化分析。 实现人体姿态识别算法：通过摄像头将待分析目标进行基于18个点以及18个关键点之间的矢量化方式，对待分析目标进行数字化和量化。人体姿态识别系统支持搭载在机器人上或建立滑轨等，因此人工智能计算设备可以运行在边缘设备上进行人体姿态辨识。

### 边缘计算效果提升
为了在带观测现场实时的观察计算结果，采用了以下的一系列基于图像处理技术和人工智能技术的方法：

1. 摄像头捕捉视频；
2. 视频存储到边缘计算设备的tf卡；
3. 将视频进行自动修整，包括：自动将视频转化为800*600分辨率的视频，无论采用任何星河的摄像头；
4. 视频修正规则：
4-1.确保画面中主体居中，包括待识别/分析对象； 
4-2.当画面中识别到多个人体的时候，以距离镜头（画面最下边缘）为距离镜头最近的主体； 
4-3.分辨率修正到800*600像素； 
4-4.视频格式修正到avi或mp4格式；
5. 将修整好的视频转化为黑白像素；
6. 在视频中以每秒钟8次的频率在每秒钟x帧（x为摄像头的每秒钟拍摄帧数）的原画视频中进行采样；
7. 采用open-pose的TensoRT Pose算法，即本git仓库中的gait_pose_analysis算法进行实时计算； 
7-1. 在图像上采用语意分割算法识别人体； 
7-2.在语意分割后的图像中做反向选择，去掉人物背景； 
7-3.采用OpenCV识别人体的眼镜、耳朵、嘴巴、鼻子、左肩膀、右肩膀、肩膀中心点、左臂关节、右臂关节、左腿关节、右腿关节等人体18关键点； 
7-4.采用SVM算法，在本地做模型优化OpenCV的识别准确度（每1000张图片中采样50张进行人工校验），确保召回率在3%以下； 
7-5.采用视觉处理中的随机森林算法，识别人体关键点之间的线段，并采用电影电视或医学资料素材在图形工作站进行深度学习，建立“最大概率人体关键点之间线段为骨骼线段”的模型； 
7-6.将建立的模型下载到边缘计算设备进行离线现场判断；
8. 将计算过的每秒钟8帧的视频合成新视频；
9. 在显示器实时显示合成的具有建立“最大概率人体关键点之间线段为骨骼线段”新视频。

### 边缘计算实现方式
建立基础：用推断引擎(Inference Engine)替代掉人工智能算法引擎(DNN/ANN Engine)，将GPU计算的算力分担。推断引擎(Inference Engine)支持硬件指令集层面的深度学习模型加速运行，同时对传统的OpenCV图像处理库也进行了指令集优化，有显着的性能与速度提升。
首先识别人体关键点，其次是进行关键点之间的连线，我们称之为“基于人体关键点的骨骼线段”，最后是通过深度学习确定点与点之间的线段可以定义为骨骼（即建立的2D模型）正确的最大概率，而后将点连接起来。
a) 输入图像；
b) 从输入图像中检测部分边界框；
c) 检测出肢体；
d) 区分图中每个人。
基于卷积神经网络（CNN），可扩展计算机视觉（OpenCV）工作负载，从而最大限度地提高性能。而创新指出在于在AI工作站部署工具包（DLDT），而非在边缘计算设备上进行。


### 产品设计思路
人体姿态识别是人工智能应用的一个重要场景，姿态识别技术不仅可以通过对单人的姿态识别了解目标对象的身体姿态情况、人体运动轨迹、肢体运动轨迹、肢体之间的协调和角度、目标对象与背景景物的位置关系等，还可以通过对群体的姿态识别获取人群的分布情况、运动状态、反常个体发现与追踪等。计算结果将被边缘计算主机输出显示器、穿戴设备、远程终端等。

### 技术实现思路
利用摄像头、监控摄像头、网络摄像头、智能穿戴设备摄像头、机器人摄像头、无人机摄像头、电脑远程摄像头、手机摄像头等，只要能以视频文件作为待分析的视频源，在数据现场直接对视频源进行计算，在数据的边缘执行即时的高吞吐量AI，使得数据现场获取实时的AI洞察的结论以及由AI驱动的动作，扭转了需要将带分析数据输入到AI工作站进行长时间计算的巨变以及减少必须发送到云的数据量。

### 创新的数据流设计
第1路数据流：基于高性能边缘计算设备和算法的现场实时计算与结果输出； 第2路数据流：启用第2路数据流的目的是以便于分析历史数据、影像资料、通过手机快捷拍摄的视频数据等进行精确的分析。第2路数据的运算点部署在云端，采用高性能人工智能工作站承担计算算力。第2路数据的管理方法是：用户只需要登录到百度云盘，上传需要分析的视频，24小时后，打开百度云盘就可以看到对应的文件夹，里面包含：视频文件18点坐标及其关键线段显示、以每秒3次采样的18个关键点数据包集合、大数据可视化分析结果展示。对物联网而言，边缘计算技术取得突破，意味着许多控制将通过本地设备实现而无需交由云端，处理过程将在本地边缘计算层完成。
采用双路数据流架构是一个创造，它的核心思路是一路数据是现场采集与分析数据的边缘计算，另一路数据流是将视频文件传输到远程AI工作站进行多算法的计算与分析，并且支持将传统的已经架设好的视频采集设备例如安防摄像头、监控摄像头、家庭云台摄像头等数以百万计的现成设备作为采集数据的数据入口，让数以百万的设备立刻具有实时的人体姿态分析功能，并为数以百万的用户提供基于人体姿态识别的科研工作与增值服务。该方式结合了人体姿态识别采集数据难度大、不同病症康复过程中人体姿态特征复杂、不同病症训练数据获取复杂等特点，采用了支持灵活的搭载设备，在行业获取更多应用场景与数据（双路数据设计，如图2-7所示，理论基础是大数据技术+人工智能技术，该方式可以让深度学习不仅仅从“此时此刻”与“架设设备”基础上开始，而是可以充分利用现有数据、现有设备作为原始启动资源，例如非侵入式设备、传统设备如架设已久的摄像头、录像影像、科研资料等，均可以成为分析对象与训练数据）。双路数据流的设计，我们可以针对未经授权的场景进行数据采集，而且可以利用丰富的视频影像资料作为训练数据。
## 使用授权说明
apache 2.0 许可，任何形式的引用或使用需要联系作者本人。作者将酌情对使用者进行授权：
授权格式：授权主体|授权时限|授权范围|授权方式|授权主机编码|授权存储卡编码|授权MAC地址
